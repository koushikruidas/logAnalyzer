spring.application.name=loganalyzer

spring.servlet.multipart.max-file-size=10MB

# ============================================
# organization details
# ============================================
ORG_ID=${ORG_ID:logs}

# ============================================
# swagger details
# ============================================
module-name=LogAnalyzer
api-version=1.0.0

# ============================================
# database details
# ============================================
spring.datasource.url=jdbc:h2:mem:mydatabase
spring.datasource.driver-class-name=org.h2.Driver
spring.datasource.username=sa
spring.datasource.password=

log.persistence.enableRelationalDB=false

# ============================================
# Elasticsearch Configuration
# ============================================
elasticsearch.host=${ELASTICSEARCH_HOST:http://es01:9200}
elasticsearch.index=log_entries
elasticsearch.username=${ELASTICSEARCH_USERNAME:elastic}
elasticsearch.password=${ELASTICSEARCH_PASSWORD}

# ============================================
# Log Ingestion & Parsing
# ============================================
log.ingest.batch-size=10000
log.ingest.default-pattern=YYYY-MM-DD HH:mm:ss

# ============================================
# Log Storage Optimization
# ============================================
log.storage.retention-days=30

# ============================================
# Log Search & Filtering
# ============================================
# Default pagination size for log search
log.search.page-size=50
# Max results to prevent performance issues
log.search.max-results=1000

# ============================================
# Log Aggregation & Statistics
# ============================================
# Enable or disable log aggregation
log.aggregation.enabled=true
# Aggregation interval (hour, day, week)
log.aggregation.interval=day
# Fields for aggregation
log.aggregation.fields=level,service

# ============================================
# Log Alerting (Threshold-based Alerts)
# ============================================
# Time window to check errors (in minutes)
log.alert.time-window-minutes=10
# Number of errors to trigger alert
log.alert.error-threshold=100
# Webhook URL for alerts (e.g., Slack, Email)
log.alert.webhook-url=

# ============================================
# Log Parsing Custom Patterns (User/Admin Defined)
# ============================================
# Allow users/admins to define custom patterns
log.parsing.allow-custom-patterns=true
# Default pattern if none provided
log.parsing.default-pattern=YYYY-MM-DD HH:mm:ss

# =============================================
# Hibernate configuration
# =============================================
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=true
spring.jpa.properties.hibernate.format_sql=true

# =============================================
# Kafka Broker Configuration
# =============================================
spring.kafka.bootstrap-servers=${KAFKA_BOOTSTRAP_SERVERS:kafka:9093}

# Security Configuration
spring.kafka.properties.security.protocol=${SPRING_KAFKA_PROPERTIES_SECURITY_PROTOCOL:SSL}
spring.kafka.properties.sasl.username=${SPRING_KAFKA_PROPERTIES_SASL_USERNAME:admin}
spring.kafka.properties.sasl.password=${SPRING_KAFKA_PROPERTIES_SASL_PASSWORD:admin-secret}

# Kafka Consumer Configuration
spring.kafka.consumer.groupId=log-consumer-group
spring.kafka.consumer.pollType=latest
spring.kafka.consumer.maxRecords=1000
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.consumer.concurrency=10
spring.kafka.consumer.topic.single=logs_ingestion
spring.kafka.consumer.topic.bulk=logs_ingestion


